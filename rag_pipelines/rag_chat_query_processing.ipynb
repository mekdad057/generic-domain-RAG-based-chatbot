{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41cfec32c4174dbcac78f3affacb77ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74f8b2a7379a4ac79894cca45918d424",
              "IPY_MODEL_834f22618abf40e6b395a0cd0c2a030d",
              "IPY_MODEL_9b936c1ce0ca464fb70356a632e3376d"
            ],
            "layout": "IPY_MODEL_cb254909c98b48a4aeaeba20bcc1230a"
          }
        },
        "74f8b2a7379a4ac79894cca45918d424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_810b8061b4d44ade8c6a0ab27327cfbc",
            "placeholder": "​",
            "style": "IPY_MODEL_0f0b02e426b041ac8b904fd243e35255",
            "value": "Batches: 100%"
          }
        },
        "834f22618abf40e6b395a0cd0c2a030d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3801657aea6545459438b62a4f07059b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1323133dcfab4c00a1e1dc8a2120713f",
            "value": 1
          }
        },
        "9b936c1ce0ca464fb70356a632e3376d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89606860bd704198bcf0db2cb97b08b8",
            "placeholder": "​",
            "style": "IPY_MODEL_47a11777ba9841fdb3f85b87f04886ef",
            "value": " 1/1 [00:00&lt;00:00, 16.99it/s]"
          }
        },
        "cb254909c98b48a4aeaeba20bcc1230a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "810b8061b4d44ade8c6a0ab27327cfbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0b02e426b041ac8b904fd243e35255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3801657aea6545459438b62a4f07059b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1323133dcfab4c00a1e1dc8a2120713f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89606860bd704198bcf0db2cb97b08b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a11777ba9841fdb3f85b87f04886ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XoEqiaCH8ghR"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet haystack-ai chroma-haystack\n",
        "!pip install --quiet --upgrade huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`read vector db from zip file`"
      ],
      "metadata": {
        "id": "IppKBEZJ81df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "# Define paths\n",
        "\n",
        "embedder_name = \"sayed0am/arabic-english-bge-m3\"\n",
        "\n",
        "vdb_path = '/content/' + 'vectordb-aren-sayed0am-testing.zip'\n",
        "extract_path = '/content/vectordb/'  # Where to extract\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Unzip\n",
        "with zipfile.ZipFile(vdb_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Documents extracted to {extract_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEiq4yMH8xhk",
        "outputId": "8cfe997b-bce1-4128-b929-2170398ab329"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents extracted to /content/vectordb/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Pipeline\n",
        "from haystack.components.builders import ChatPromptBuilder, PromptBuilder\n",
        "from haystack.dataclasses import ChatMessage\n",
        "from haystack.utils import Secret\n",
        "from haystack.components.generators.chat import HuggingFaceAPIChatGenerator, HuggingFaceLocalChatGenerator\n",
        "from haystack.components.generators import HuggingFaceLocalGenerator\n",
        "from haystack.components.routers import ConditionalRouter\n",
        "from haystack_integrations.components.retrievers.chroma import ChromaEmbeddingRetriever\n",
        "from haystack_integrations.document_stores.chroma import ChromaDocumentStore\n",
        "\n",
        "\n",
        "from haystack import component\n",
        "from haystack.components.embedders import SentenceTransformersTextEmbedder\n"
      ],
      "metadata": {
        "id": "3NBCODeS9sXp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_prompt_template =\"\"\"\n",
        "ROLE AND CONTEXT:\n",
        "You are a fluent arabic assitant, You are a knowledgeable assistant, Your task is to provide accurate and detailed answers to queries using the provided excerpts and references from useful resources to support your answers.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Use History to disambiguate the query\n",
        "2. Identify the relevant sections to only the query of the excerpts provided.\n",
        "3. If the query cannot be answered given the provided documents, return 'no_answer'\n",
        "2. Otherwise provide a *concise* and informative response to only the query based on relevant sections of the excerpts provided.\n",
        "3. Ensure your responses are relevant, clear and easy to understand.\n",
        "\n",
        "EXCERPTS:\n",
        "{% for doc in documents %}\n",
        "    excerpt: {{ doc.content }}\n",
        "{% endfor %}\n",
        "\n",
        "CONSIDERATIONS:\n",
        "- History is only used to disambiguate the query.\n",
        "- If you can't give an answer, it's okay to output one single word 'no_answer'\n",
        "- if you can give an answer, only answer the query without answering the History\n",
        "\n",
        "Query History:\n",
        "{% for q in history %}\n",
        "    query {{loop.index}}: {{ q }}\n",
        "{% endfor %}\n",
        "\n",
        "Query: {{query}}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "fallback_prompt_template = \"\"\"you are fluent arabic virtual assistant, you maintain your image as an arabic assitant no matter what they user says and you answer in arabic only.\n",
        "User entered a query that cannot be answered with the excerpts provided.\n",
        "The query was: {{query}}.\n",
        "Let the user know that you can't answer his question, but you're ready to help him with the next question. Be brief.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MvsCagFc9yco"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize document store (using Chroma as in your example)\n",
        "document_store = ChromaDocumentStore(\n",
        "    embedding_function='default',\n",
        "    persist_path='/content/vectordb'\n",
        ")\n",
        "\n",
        "query_embedder = SentenceTransformersTextEmbedder(model=embedder_name)\n",
        "retriever = ChromaEmbeddingRetriever(document_store=document_store, top_k=5)\n",
        "\n",
        "template1 = [ChatMessage.from_user(main_prompt_template)]\n",
        "main_promptbuilder = ChatPromptBuilder(template=template1, required_variables=[\"history\",\"query\"], variables = ['query', 'history', 'documents'])\n",
        "template2 = [ChatMessage.from_user(fallback_prompt_template)]\n",
        "fallback_promptbuilder = ChatPromptBuilder(template=template2, required_variables=[\"history\"])\n",
        "\n",
        "# main_llm = HuggingFaceLocalChatGenerator(model=\"Qwen/Qwen2.5-3B-Instruct\")\n",
        "main_llm = HuggingFaceLocalChatGenerator(model=\"microsoft/Phi-4-mini-instruct\")\n",
        "\n",
        "\n",
        "fallback_llm = HuggingFaceLocalChatGenerator(model=\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
        "\n",
        "\n",
        "from typing import List\n",
        "@component\n",
        "class NoOpComponent:\n",
        "  @component.output_types(query=str,history=List[str])\n",
        "  def run(self, history: List[str], **kwargs):\n",
        "    return {'history':history, 'query':history[-1]}\n",
        "\n",
        "conditional_router = ConditionalRouter([\n",
        "    {\n",
        "        \"condition\": \"{{'no_answer' not in replies[0].text }}\",\n",
        "        \"output\": \"{{replies}}\",\n",
        "        \"output_name\": \"replies\",\n",
        "        \"output_type\": list[ChatMessage],\n",
        "    },\n",
        "    {\n",
        "        \"condition\": \"{{'no_answer' in replies[0].text }}\",\n",
        "        \"output\": \"{{query}}\",\n",
        "        \"output_name\": \"go_to_fallback\",\n",
        "        \"output_type\": str,\n",
        "    },\n",
        "], unsafe = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STJmi6Kw9LUS",
        "outputId": "c84d23d9-f745-4275-b639-1962acd60430"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:haystack.components.routers.conditional_router:Unsafe mode is enabled. This allows execution of arbitrary code in the Jinja template. Use this only if you trust the source of the template.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup pipeline\n",
        "pipeline = Pipeline()\n",
        "pipeline.add_component('distributer', NoOpComponent())\n",
        "pipeline.add_component('embedder', query_embedder)\n",
        "pipeline.add_component('retriever', retriever)\n",
        "pipeline.add_component('main_promptbuilder', main_promptbuilder)\n",
        "pipeline.add_component('fallback_promptbuilder', fallback_promptbuilder)\n",
        "pipeline.add_component('main_llm', main_llm)\n",
        "pipeline.add_component('fallback_llm', fallback_llm)\n",
        "pipeline.add_component('conditional_router', conditional_router)\n",
        "\n",
        "pipeline.connect('distributer.query', 'embedder.text')\n",
        "pipeline.connect('distributer.query', 'main_promptbuilder.query')\n",
        "pipeline.connect('distributer.history', 'main_promptbuilder.history')\n",
        "pipeline.connect('distributer.query', 'conditional_router.query')\n",
        "\n",
        "pipeline.connect('embedder.embedding', 'retriever.query_embedding')\n",
        "pipeline.connect('retriever.documents', 'main_promptbuilder.documents')\n",
        "\n",
        "pipeline.connect('main_promptbuilder.prompt', 'main_llm.messages')\n",
        "\n",
        "pipeline.connect('main_llm.replies', 'conditional_router.replies')\n",
        "\n",
        "pipeline.connect('conditional_router.go_to_fallback', 'fallback_promptbuilder.query')\n",
        "pipeline.connect('fallback_promptbuilder.prompt', 'fallback_llm.messages')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us_azRqe-_l-",
        "outputId": "e7abeb06-f121-4088-e45b-cba5f5a720be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7faa997ef8d0>\n",
              "🚅 Components\n",
              "  - distributer: NoOpComponent\n",
              "  - embedder: SentenceTransformersTextEmbedder\n",
              "  - retriever: ChromaEmbeddingRetriever\n",
              "  - main_promptbuilder: ChatPromptBuilder\n",
              "  - fallback_promptbuilder: ChatPromptBuilder\n",
              "  - main_llm: HuggingFaceLocalChatGenerator\n",
              "  - fallback_llm: HuggingFaceLocalChatGenerator\n",
              "  - conditional_router: ConditionalRouter\n",
              "🛤️ Connections\n",
              "  - distributer.query -> embedder.text (str)\n",
              "  - distributer.query -> main_promptbuilder.query (str)\n",
              "  - distributer.history -> main_promptbuilder.history (List[str])\n",
              "  - distributer.query -> conditional_router.query (str)\n",
              "  - embedder.embedding -> retriever.query_embedding (List[float])\n",
              "  - retriever.documents -> main_promptbuilder.documents (List[Document])\n",
              "  - main_promptbuilder.prompt -> main_llm.messages (List[ChatMessage])\n",
              "  - fallback_promptbuilder.prompt -> fallback_llm.messages (List[ChatMessage])\n",
              "  - main_llm.replies -> conditional_router.replies (List[ChatMessage])\n",
              "  - conditional_router.go_to_fallback -> fallback_promptbuilder.query (str)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random  # Added for shuffling\n",
        "\n",
        "HISTORY_LENGTH = 3\n",
        "\n",
        "def run(messages_history: str, history_length):\n",
        "  results = pipeline.run({\n",
        "      'distributer': {'history': messages_history[-history_length:]}, # extracts last sent messages\n",
        "      }, include_outputs_from={'retriever','main_promptbuilder', 'main_llm'})\n",
        "  return results\n",
        "\n",
        "def get_is_fallback(results):\n",
        "  return results.get('fallback_llm') is not None\n",
        "\n",
        "def get_context(results):\n",
        "  retriever_output = results[\"retriever\"]['documents']\n",
        "  return retriever_output\n",
        "\n",
        "\n",
        "def get_reply(results):\n",
        "  response = results.get('conditional_router') or results.get('fallback_llm')\n",
        "  print('from conditional router:', results.get('conditional_router') is not None)\n",
        "  print('from fallback llm:', results.get('fallback_llm') is not None)\n",
        "  reply = response['replies'][0].text.replace('\\n', '')\n",
        "  return reply\n"
      ],
      "metadata": {
        "id": "GOX1o7tSBTye"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    \"\"\"مرحباً كيف حالك؟\"\"\",\n",
        "    \"\"\"أريد أن أعلم ما هو النظام المتبع في المشروع؟\"\"\"\n",
        "]\n",
        "\n",
        "one_message = []\n",
        "results = run(messages, HISTORY_LENGTH)\n",
        "print(get_reply(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "41cfec32c4174dbcac78f3affacb77ed",
            "74f8b2a7379a4ac79894cca45918d424",
            "834f22618abf40e6b395a0cd0c2a030d",
            "9b936c1ce0ca464fb70356a632e3376d",
            "cb254909c98b48a4aeaeba20bcc1230a",
            "810b8061b4d44ade8c6a0ab27327cfbc",
            "0f0b02e426b041ac8b904fd243e35255",
            "3801657aea6545459438b62a4f07059b",
            "1323133dcfab4c00a1e1dc8a2120713f",
            "89606860bd704198bcf0db2cb97b08b8",
            "47a11777ba9841fdb3f85b87f04886ef"
          ]
        },
        "id": "ydvUcTNxCfq6",
        "outputId": "5de41bda-0840-4fff-a303-f2fa119ed7d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41cfec32c4174dbcac78f3affacb77ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from conditional router: True\n",
            "from fallback llm: False\n",
            "نظام التقييم يعتمد على ستة مقاييس لتقييم الأداء، بما في ذلك منهجية LLM-as-Judge، حيث يقوم نموذج لغوي كبير بتقييم النظام. يستخدم نظام RAG مع مراحل الفهرسة والإجابة. تُستخدم لغة بايثون و Snowflake لعمليات الحفظ والاسترجاع، مع إطار عمل Haystack-ais لفهم وتخصيص محادثة التفاعل. كان الهدف من المشروع هو تصميم ووكلب محادثة افتراضي يراعي خصوصية المعلومات ويتيح التفاعل مع مصادر محددة مسبقاً.\n"
          ]
        }
      ]
    }
  ]
}